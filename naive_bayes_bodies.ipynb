{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading subjects data\n",
    "data_b = pd.read_csv(\"dbworld_bodies_stemmed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate features and class\n",
    "xb = data_b.iloc[:,1:-1]\n",
    "yb = data_b['CLASS']\n",
    "\n",
    "# yb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data for training and testing\n",
    "xb_train, xb_test, yb_train, yb_test = train_test_split(xb,yb,test_size = 0.2,random_state = 20)\n",
    "\n",
    "\n",
    "# xb_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate train features with train class\n",
    "trainb = pd.concat([xb_train, yb_train], axis=1)\n",
    "# trainb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate spam and ham msgs\n",
    "classgrpb = trainb.groupby('CLASS')\n",
    "spam_bf = classgrpb.get_group(1)\n",
    "ham_bf = classgrpb.get_group(0)\n",
    "# spam_bf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing class column at the end \n",
    "spam_b = spam_bf.iloc[:,:-1]\n",
    "ham_b = ham_bf.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 51\n"
     ]
    }
   ],
   "source": [
    "#probability of spam and ham messages\n",
    "p_spamb = len(spam_b) / len(trainb)\n",
    "p_hamb = len(ham_b) / len(trainb)\n",
    "print(len(spam_b), len(trainb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    165\n",
       "2     136\n",
       "24    152\n",
       "60     83\n",
       "18    251\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting words in spam and ham of each mail\n",
    "nspamb_rows = spam_b.sum(axis=1)\n",
    "nspamb_rows.head()\n",
    "\n",
    "nhamb_rows = ham_b.sum(axis=1)\n",
    "nhamb_rows.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting words of spam and ham of all mails\n",
    "nspamb = nspamb_rows.sum(axis=0)\n",
    "nhamb = nhamb_rows.sum(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laplace parameter and number of classes\n",
    "k = 1\n",
    "vocab = list(xb_train.columns)\n",
    "n_vocab = len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities of words given spam or ham\n",
    "prob_word_given_spam = {word:0 for word in vocab}\n",
    "prob_word_given_ham = {word:0 for word in vocab}\n",
    "\n",
    "\n",
    "for word in vocab:\n",
    "   nword_given_spam = spam_b[word].sum()\n",
    "   pword_given_spam = (nword_given_spam + k) / (nspamb + (k*n_vocab))\n",
    "   prob_word_given_spam[word] = pword_given_spam\n",
    "\n",
    "   nword_given_ham = ham_b[word].sum() \n",
    "   pword_given_ham = (nword_given_ham + k) / (nhamb + (k*n_vocab))\n",
    "   prob_word_given_ham[word] = pword_given_ham\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def predict(test):\n",
    "\n",
    "    prob_spam_given_mail = np.log(p_spamb)\n",
    "    prob_ham_given_mail = np.log(p_hamb)\n",
    "    # print(prob_spam_given_mail,prob_spam_given_mail)\n",
    "    test = test.reset_index()\n",
    "    test = test.iloc[:,1:]\n",
    "    # print(test)\n",
    "    l = []\n",
    "    for i in range(test.shape[0]):\n",
    "        # for word in vocab:\n",
    "        for word in vocab:\n",
    "            if test.loc[i][word] == 1:\n",
    "                prob_spam_given_mail += np.log(prob_word_given_spam[word])\n",
    "                prob_ham_given_mail += np.log(prob_word_given_ham[word])\n",
    "\n",
    "            \n",
    "        # print(prob_ham_given_mail,prob_ham_given_mail)\n",
    "        if prob_spam_given_mail > prob_ham_given_mail:\n",
    "            l.append(1)\n",
    "        elif prob_ham_given_mail > prob_spam_given_mail:\n",
    "            l.append(0)\n",
    "        else:\n",
    "            l.append(0.5)\n",
    "\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting test data\n",
    "yb_test_pred = predict(xb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating f measure\n",
    "def fmeasure(pred_values, true_values):\n",
    "\t\n",
    "\tTP, TN, FP, FN = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "\tfor p, a in zip(pred_values, true_values):\n",
    "\t\tif p == 0 and a == 0:\n",
    "\t\t\tTP = TP + 1\n",
    "\t\telif p == 1 and a == 1:\n",
    "\t\t\tTN = TN + 1\n",
    "\t\telif p == 0 and a == 1:\n",
    "\t\t\tFP = FP + 1\n",
    "\t\telif p == 1 and a == 0:\n",
    "\t\t\tFN = FN + 1\n",
    "\n",
    "\tPre = TP / (TP + FP)\n",
    "\tRec = TP / (TP + FN)\n",
    "\n",
    "\tf_measure = (2 * Pre * Rec) / (Pre + Rec)\n",
    "\n",
    "\treturn f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_measure of email body:  0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "#Printing f measure\n",
    "f_measure_bodies = fmeasure(yb_test,yb_test_pred)\n",
    "print(\"f_measure of email body: \",f_measure_bodies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Email Subject provides better classification since it has more f measure value compared to email body"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3dc909af7eef96a37a460b9be5b688fc0a118680601022b0514c6f951bac496"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
